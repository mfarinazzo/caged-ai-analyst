{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f62f4b66-0f05-4937-a027-6d6eb235a0d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Baixando dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad9ec15d-f889-4197-9b24-b9c4a940d42e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting py7zr\n",
      "  Downloading py7zr-1.1.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting texttable (from py7zr)\n",
      "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting pycryptodomex>=3.20.0 (from py7zr)\n",
      "  Downloading pycryptodomex-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting brotli>=1.2.0 (from py7zr)\n",
      "  Downloading brotli-1.2.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: psutil in /databricks/python3/lib/python3.12/site-packages (from py7zr) (5.9.0)\n",
      "Collecting backports.zstd>=1.0.0 (from py7zr)\n",
      "  Downloading backports_zstd-1.3.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (6.9 kB)\n",
      "Collecting pyppmd>=1.3.1 (from py7zr)\n",
      "  Downloading pyppmd-1.3.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting pybcj>=1.0.6 (from py7zr)\n",
      "  Downloading pybcj-1.0.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting multivolumefile>=0.2.3 (from py7zr)\n",
      "  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting inflate64>=1.0.4 (from py7zr)\n",
      "  Downloading inflate64-1.0.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
      "Downloading py7zr-1.1.0-py3-none-any.whl (71 kB)\n",
      "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/71.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.4/71.3 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m71.3/71.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading backports_zstd-1.3.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (494 kB)\n",
      "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/494.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m491.5/494.2 kB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m494.2/494.2 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading brotli-1.2.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.4 MB)\n",
      "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/1.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading inflate64-1.0.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (100 kB)\n",
      "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/100.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m92.2/100.6 kB\u001b[0m \u001b[31m172.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m100.6/100.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
      "Downloading pybcj-1.0.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (51 kB)\n",
      "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/51.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pycryptodomex-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
      "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/2.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m125.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyppmd-1.3.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (144 kB)\n",
      "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/144.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m144.3/144.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
      "Installing collected packages: texttable, brotli, pyppmd, pycryptodomex, pybcj, multivolumefile, inflate64, backports.zstd, py7zr\n",
      "Successfully installed backports.zstd-1.3.0 brotli-1.2.0 inflate64-1.0.4 multivolumefile-0.2.3 py7zr-1.1.0 pybcj-1.0.7 pycryptodomex-3.23.0 pyppmd-1.3.1 texttable-1.7.0\n",
      "\u001b[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install py7zr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32d0ba4b-01a4-4c61-8e70-853db26ca00f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Conectando com o Blob Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c92d7df-3b78-4bff-a876-f8ef19751ec4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectado ao Storage: cagedstorage\n"
     ]
    }
   ],
   "source": [
    "STORAGE_ACCOUNT = \"\"\n",
    "\n",
    "ACCESS_KEY = \"\"\n",
    "\n",
    "spark.conf.set(\n",
    "    f\"fs.azure.account.key.{STORAGE_ACCOUNT}.blob.core.windows.net\",\n",
    "    ACCESS_KEY\n",
    ")\n",
    "\n",
    "BRONZE_CONTAINER = \"bronze\"\n",
    "SILVER_CONTAINER = \"silver\"\n",
    "\n",
    "BASE_PATH_BRONZE = f\"wasbs://{BRONZE_CONTAINER}@{STORAGE_ACCOUNT}.blob.core.windows.net/\"\n",
    "BASE_PATH_SILVER = f\"wasbs://{SILVER_CONTAINER}@{STORAGE_ACCOUNT}.blob.core.windows.net/movimentacoes_detalhadas\"\n",
    "\n",
    "print(f\"Conectado ao Storage: {STORAGE_ACCOUNT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f6f5573-6205-4779-80e3-94d531753e3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Iniciando varredura no Azure...\n",
      "[INFO] Arquivos .7z encontrados: 71\n",
      "[INFO] Processando 71 arquivos extra√≠dos...\n",
      "[INFO] Gravando tabela Delta na camada Silver...\n",
      "[INFO] Processamento conclu√≠do com sucesso em: wasbs://silver@cagedstorage.blob.core.windows.net/movimentacoes_detalhadas\n",
      "[INFO] Arquivos tempor√°rios removidos.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import py7zr\n",
    "from pyspark.sql.functions import col, when, regexp_replace\n",
    "from pyspark.sql.types import DoubleType, IntegerType\n",
    "\n",
    "# --- CONFIGURA√á√ïES ---\n",
    "STORAGE_ACCOUNT = \"\"\n",
    "CONTAINER_BRONZE = \"bronze\"\n",
    "CONTAINER_SILVER = \"silver\"\n",
    "\n",
    "# Insira sua chave de acesso (KEY) abaixo\n",
    "ACCESS_KEY = \"\"\n",
    "\n",
    "# Configura√ß√£o de credenciais Spark\n",
    "spark.conf.set(\n",
    "    f\"fs.azure.account.key.{STORAGE_ACCOUNT}.blob.core.windows.net\",\n",
    "    ACCESS_KEY\n",
    ")\n",
    "\n",
    "# Caminhos (Protocolo WASBS)\n",
    "PATH_BRONZE = f\"wasbs://{CONTAINER_BRONZE}@{STORAGE_ACCOUNT}.blob.core.windows.net/\"\n",
    "PATH_SILVER = f\"wasbs://{CONTAINER_SILVER}@{STORAGE_ACCOUNT}.blob.core.windows.net/movimentacoes_detalhadas\"\n",
    "DIR_TEMP_LOCAL = \"/tmp/tmp_caged_processamento/\"\n",
    "\n",
    "def registrar_log(msg):\n",
    "    print(f\"[INFO] {msg}\")\n",
    "\n",
    "def listar_arquivos_recursivo(caminho_base):\n",
    "    lista_arquivos = []\n",
    "    try:\n",
    "        items = dbutils.fs.ls(caminho_base)\n",
    "        for item in items:\n",
    "            if item.isDir():\n",
    "                lista_arquivos.extend(listar_arquivos_recursivo(item.path))\n",
    "            elif item.path.endswith(\".7z\"):\n",
    "                lista_arquivos.append(item.path)\n",
    "    except Exception as e:\n",
    "        print(f\"[AVISO] Erro ao listar {caminho_base}: {e}\")\n",
    "    return lista_arquivos\n",
    "\n",
    "# --- ETAPA 1: C√ìPIA E EXTRA√á√ÉO ---\n",
    "registrar_log(\"Iniciando varredura no Azure...\")\n",
    "\n",
    "if os.path.exists(DIR_TEMP_LOCAL):\n",
    "    shutil.rmtree(DIR_TEMP_LOCAL)\n",
    "os.makedirs(DIR_TEMP_LOCAL, exist_ok=True)\n",
    "\n",
    "arquivos_azure = listar_arquivos_recursivo(PATH_BRONZE)\n",
    "registrar_log(f\"Arquivos .7z encontrados: {len(arquivos_azure)}\")\n",
    "\n",
    "arquivos_processar = []\n",
    "\n",
    "for arquivo_remoto in arquivos_azure:\n",
    "    nome_arquivo = arquivo_remoto.split(\"/\")[-1]\n",
    "    caminho_local_7z = os.path.join(DIR_TEMP_LOCAL, nome_arquivo)\n",
    "    \n",
    "    # Otimiza√ß√£o: S√≥ copia se n√£o existir localmente (caso o cluster n√£o tenha reiniciado)\n",
    "    if not os.path.exists(caminho_local_7z):\n",
    "        try:\n",
    "            dbutils.fs.cp(arquivo_remoto, f\"file:{caminho_local_7z}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ERRO] Falha ao copiar {nome_arquivo}: {e}\")\n",
    "            continue\n",
    "\n",
    "    try:\n",
    "        with py7zr.SevenZipFile(caminho_local_7z, mode='r') as z:\n",
    "            z.extractall(path=DIR_TEMP_LOCAL)\n",
    "            for nome in z.getnames():\n",
    "                # Filtra apenas os arquivos de dados (txt ou csv)\n",
    "                if nome.lower().endswith(\".txt\") or nome.lower().endswith(\".csv\"):\n",
    "                    arquivos_processar.append(os.path.join(DIR_TEMP_LOCAL, nome))\n",
    "        \n",
    "        # Remove o compactado para liberar espa√ßo\n",
    "        os.remove(caminho_local_7z)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERRO] Falha ao descompactar {nome_arquivo}: {e}\")\n",
    "\n",
    "# --- ETAPA 2: PROCESSAMENTO SPARK ---\n",
    "if arquivos_processar:\n",
    "    registrar_log(f\"Processando {len(arquivos_processar)} arquivos extra√≠dos...\")\n",
    "\n",
    "    try:\n",
    "        # CORRE√á√ÉO: Encoding UTF-8 para suportar acentos corretamente\n",
    "        df_bruto = spark.read \\\n",
    "            .option(\"header\", \"true\") \\\n",
    "            .option(\"delimiter\", \";\") \\\n",
    "            .option(\"encoding\", \"UTF-8\") \\\n",
    "            .option(\"inferSchema\", \"false\") \\\n",
    "            .csv(f\"file:{DIR_TEMP_LOCAL}\")\n",
    "\n",
    "        # Mapeamento exato conforme colunas informadas\n",
    "        df_final = df_bruto.select(\n",
    "            col(\"compet√™nciamov\").cast(IntegerType()).alias(\"competencia\"),\n",
    "            col(\"munic√≠pio\").cast(IntegerType()).alias(\"id_municipio\"),\n",
    "            col(\"subclasse\").alias(\"id_cnae_subclasse\"),\n",
    "            col(\"cbo2002ocupa√ß√£o\").alias(\"id_cbo\"),\n",
    "            col(\"saldomovimenta√ß√£o\").cast(IntegerType()).alias(\"saldo_movimentacao\"),\n",
    "            col(\"tipomovimenta√ß√£o\").cast(IntegerType()).alias(\"tipo_movimentacao\"),\n",
    "            col(\"ra√ßacor\").cast(IntegerType()).alias(\"id_raca\"),\n",
    "            col(\"sexo\").cast(IntegerType()).alias(\"id_sexo\"),\n",
    "            col(\"graudeinstru√ß√£o\").cast(IntegerType()).alias(\"id_instrucao\"),\n",
    "            col(\"idade\").cast(IntegerType()).alias(\"idade\"),\n",
    "            \n",
    "            # Tratamento num√©rico (V√≠rgula para Ponto)\n",
    "            regexp_replace(col(\"sal√°rio\"), \",\", \".\").cast(DoubleType()).alias(\"salario_bruto\"),\n",
    "            col(\"unidadesal√°rioc√≥digo\").cast(IntegerType()).alias(\"tipo_unidade_salarial\"),\n",
    "            regexp_replace(col(\"horascontratuais\"), \",\", \".\").cast(DoubleType()).alias(\"horas_contratuais\")\n",
    "        ).withColumn(\n",
    "            # Regra de c√°lculo salarial mensalizado\n",
    "            \"salario_mensal_final\",\n",
    "            when(col(\"tipo_unidade_salarial\") == 5, col(\"salario_bruto\")) # Mensal\n",
    "            .when(col(\"tipo_unidade_salarial\") == 1, col(\"salario_bruto\") * col(\"horas_contratuais\") * 4.33) # Horista\n",
    "            .when(col(\"tipo_unidade_salarial\") == 3, col(\"salario_bruto\") * 4.33) # Semanal\n",
    "            .when(col(\"tipo_unidade_salarial\") == 4, col(\"salario_bruto\") * 2) # Quinzenal\n",
    "            .otherwise(None)\n",
    "        ).filter(\n",
    "            # Filtros de consist√™ncia de dados\n",
    "            (col(\"salario_mensal_final\") >= 1000) & \n",
    "            (col(\"salario_mensal_final\") <= 50000) &\n",
    "            (col(\"idade\") >= 14) & \n",
    "            (col(\"idade\") <= 80)\n",
    "        ).withColumn(\"ano\", (col(\"competencia\") / 100).cast(IntegerType())) \\\n",
    "         .withColumn(\"mes\", (col(\"competencia\") % 100).cast(IntegerType()))\n",
    "\n",
    "        # --- ETAPA 3: GRAVA√á√ÉO ---\n",
    "        registrar_log(\"Gravando tabela Delta na camada Silver...\")\n",
    "        \n",
    "        df_final.write \\\n",
    "            .format(\"delta\") \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .partitionBy(\"ano\", \"mes\") \\\n",
    "            .save(PATH_SILVER)\n",
    "\n",
    "        registrar_log(f\"Processamento conclu√≠do com sucesso em: {PATH_SILVER}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERRO CR√çTICO NO SPARK] {e}\")\n",
    "        # Importante: N√£o relan√ßa o erro imediatamente para permitir a limpeza do finally\n",
    "    \n",
    "    finally:\n",
    "        # Limpeza obrigat√≥ria do disco tempor√°rio\n",
    "        if os.path.exists(DIR_TEMP_LOCAL):\n",
    "            shutil.rmtree(DIR_TEMP_LOCAL)\n",
    "            registrar_log(\"Arquivos tempor√°rios removidos.\")\n",
    "else:\n",
    "    registrar_log(\"Nenhum arquivo encontrado para processar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75ce6ce5-dfcc-4109-a899-651b09c7f4e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### criando catalogo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3012c4d-7054-459c-a1ec-5aff243c4297",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Criando Banco de Dados no Cat√°logo Legado...\n",
      "2. Registrando tabela apontando para: wasbs://silver@cagedstorage.blob.core.windows.net/movimentacoes_detalhadas\n",
      "Tabela 'hive_metastore.banco_caged.tabela_silver' registrada com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Garante que as chaves est√£o na sess√£o\n",
    "spark.conf.set(\n",
    "    f\"fs.azure.account.key.{STORAGE_ACCOUNT}.blob.core.windows.net\",\n",
    "    ACCESS_KEY\n",
    ")\n",
    "\n",
    "CAMINHO_SILVER = f\"wasbs://{CONTAINER_SILVER}@{STORAGE_ACCOUNT}.blob.core.windows.net/movimentacoes_detalhadas\"\n",
    "\n",
    "print(\"1. Criando Banco de Dados no Cat√°logo Legado...\")\n",
    "# Usamos 'hive_metastore' para fugir da trava do Unity Catalog\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS hive_metastore.banco_caged\")\n",
    "\n",
    "print(f\"2. Registrando tabela apontando para: {CAMINHO_SILVER}\")\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS hive_metastore.banco_caged.tabela_silver\n",
    "    USING DELTA\n",
    "    LOCATION '{CAMINHO_SILVER}'\n",
    "\"\"\")\n",
    "\n",
    "print(\"Tabela 'hive_metastore.banco_caged.tabela_silver' registrada com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "973be89d-cfe5-4358-aab3-ddefe11cbabf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando sa√∫de da tabela...\n",
      "Total de linhas na tabela: 215808549\n",
      "\n",
      "Anos dispon√≠veis:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ano</th><th>qtd</th></tr></thead><tbody><tr><td>2020</td><td>22153258</td></tr><tr><td>2021</td><td>30652934</td></tr><tr><td>2022</td><td>37294617</td></tr><tr><td>2023</td><td>39359513</td></tr><tr><td>2024</td><td>43610336</td></tr><tr><td>2025</td><td>42737891</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         2020,
         22153258
        ],
        [
         2021,
         30652934
        ],
        [
         2022,
         37294617
        ],
        [
         2023,
         39359513
        ],
        [
         2024,
         43610336
        ],
        [
         2025,
         42737891
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "ano",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "qtd",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üëÄ Amostra dos dadosüëÄüëÄüëÄüëÄ:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>competencia</th><th>id_municipio</th><th>id_cnae_subclasse</th><th>id_cbo</th><th>saldo_movimentacao</th><th>tipo_movimentacao</th><th>id_raca</th><th>id_sexo</th><th>id_instrucao</th><th>idade</th><th>salario_bruto</th><th>tipo_unidade_salarial</th><th>horas_contratuais</th><th>salario_mensal_final</th><th>ano</th><th>mes</th></tr></thead><tbody><tr><td>202207</td><td>354100</td><td>8299799</td><td>517410</td><td>-1</td><td>31</td><td>6</td><td>1</td><td>7</td><td>37</td><td>1607.97</td><td>5</td><td>44.0</td><td>1607.97</td><td>2022</td><td>7</td></tr><tr><td>202207</td><td>354980</td><td>9329899</td><td>521140</td><td>-1</td><td>43</td><td>3</td><td>3</td><td>7</td><td>34</td><td>1617.32</td><td>5</td><td>44.0</td><td>1617.32</td><td>2022</td><td>7</td></tr><tr><td>202207</td><td>355030</td><td>8130300</td><td>783225</td><td>-1</td><td>31</td><td>1</td><td>1</td><td>7</td><td>34</td><td>1239.8</td><td>5</td><td>44.0</td><td>1239.8</td><td>2022</td><td>7</td></tr><tr><td>202207</td><td>110020</td><td>6021700</td><td>376320</td><td>-1</td><td>31</td><td>6</td><td>3</td><td>9</td><td>38</td><td>2348.66</td><td>5</td><td>30.0</td><td>2348.66</td><td>2022</td><td>7</td></tr><tr><td>202207</td><td>430930</td><td>2822401</td><td>731155</td><td>-1</td><td>31</td><td>2</td><td>1</td><td>7</td><td>48</td><td>2889.02</td><td>5</td><td>44.0</td><td>2889.02</td><td>2022</td><td>7</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         202207,
         354100,
         "8299799",
         "517410",
         -1,
         31,
         6,
         1,
         7,
         37,
         1607.97,
         5,
         44,
         1607.97,
         2022,
         7
        ],
        [
         202207,
         354980,
         "9329899",
         "521140",
         -1,
         43,
         3,
         3,
         7,
         34,
         1617.32,
         5,
         44,
         1617.32,
         2022,
         7
        ],
        [
         202207,
         355030,
         "8130300",
         "783225",
         -1,
         31,
         1,
         1,
         7,
         34,
         1239.8,
         5,
         44,
         1239.8,
         2022,
         7
        ],
        [
         202207,
         110020,
         "6021700",
         "376320",
         -1,
         31,
         6,
         3,
         9,
         38,
         2348.66,
         5,
         30,
         2348.66,
         2022,
         7
        ],
        [
         202207,
         430930,
         "2822401",
         "731155",
         -1,
         31,
         2,
         1,
         7,
         48,
         2889.02,
         5,
         44,
         2889.02,
         2022,
         7
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "competencia",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "id_municipio",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "id_cnae_subclasse",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "id_cbo",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "saldo_movimentacao",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "tipo_movimentacao",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "id_raca",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "id_sexo",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "id_instrucao",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "idade",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "salario_bruto",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "tipo_unidade_salarial",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "horas_contratuais",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "salario_mensal_final",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "ano",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "mes",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- DIAGN√ìSTICO DA TABELA ---\n",
    "spark.conf.set(f\"fs.azure.account.key.{STORAGE_ACCOUNT}.blob.core.windows.net\", ACCESS_KEY)\n",
    "\n",
    "print(\"Verificando sa√∫de da tabela...\")\n",
    "\n",
    "# 1. Conta quantas linhas existem no total\n",
    "total = spark.sql(\"SELECT count(*) FROM hive_metastore.banco_caged.tabela_silver\").collect()[0][0]\n",
    "print(f\"Total de linhas na tabela: {total}\")\n",
    "\n",
    "if total > 0:\n",
    "    # 2. Se tiver dados, mostra quais ANOS est√£o dispon√≠veis\n",
    "    print(\"\\nAnos dispon√≠veis:\")\n",
    "    display(spark.sql(\"SELECT ano, count(*) as qtd FROM hive_metastore.banco_caged.tabela_silver GROUP BY ano ORDER BY ano\"))\n",
    "    \n",
    "    # 3. Mostra uma amostra de 5 linhas para checar se os c√≥digos est√£o certos\n",
    "    print(\"\\n Amostra dos dados :\")\n",
    "    display(spark.sql(\"SELECT * FROM hive_metastore.banco_caged.tabela_silver LIMIT 5\"))\n",
    "else:\n",
    "    print(\"\\nA TABELA EST√Å VAZIA!\")\n",
    "    print(\"Isso significa que o passo de 'Processamento' (Etapa 2) n√£o salvou nada.\")\n",
    "    print(\"SOLU√á√ÉO: Volte na c√©lula de processamento (aquela grande do Python) e rode ela novamente agora que o Cluster est√° corrigido.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "505e745e-882d-4ef5-8a1d-6ac4124585a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- DIAGN√ìSTICO DA TABELA ---\n",
    "spark.conf.set(f\"fs.azure.account.key.{STORAGE_ACCOUNT}.blob.core.windows.net\", ACCESS_KEY)\n",
    "\n",
    "df = spark.sql(\"\"\"\n",
    "CREATE TABLE cageddatabricks.banco_caged.tabela_silver\n",
    "USING DELTA\n",
    "AS SELECT * FROM hive_metastore.banco_caged.tabela_silver;\n",
    "                  \"\"\")\n",
    "\n",
    "# display(df)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
